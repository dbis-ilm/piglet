akka {
	loggers = ["akka.event.slf4j.Slf4jLogger"]
	loglevel = "DEBUG"
	logging-filter = "akka.event.slf4j.Slf4jLoggingFilter"
}

#######

# REPL related settings

common.jar = "common/target/scala-2.11/common_2.11-0.3.jar"

repl {

	# name of the file to save REPL commands to
	# relative to ~/.piglet/
	history = ".history"
}

#######

# configure materialization manager settings

materialization {
	# the base directory where all related files are stored in
	#basedir = "tachyon://172.21.249.61:19998/user/stha1in/piglet/"
  basedir = "hdfs:///user/stha1in/piglet/"
	#basedir = "file:///tmp/piglet/mat/"

	# the file storing the mappings tree-hash --> materialization file name
	mapfile = "mat_mappings.json"
}

#######

# StatServer

statserver {
	port = 8000
	#url = http://141.24.212.161:8000/
}

#######



# HDFS service related settings

hdfs {

	# these are the hdfs configuration files. Adjust these to match your installation
	coresite = "core-site.xml"
	hdfssite = "hdfs-site.xml"
}

#######

# configure settings for all supported backends

backends {

	default = "spark"

	# name of the backend as it is referenced in the --backend option
	flink {
		# the class that implements necessary methods to get this backend's configuration
		conf = "dbis.piglet.backends.flink.FlinkConf"
		jar = "flinklib/target/scala-2.11/flinklib-assembly-0.3.jar"
		generator =  {
		              class  =  "dbis.piglet.codegen.flink.FlinkCodeGenStrategy"
		              extension = "scala"
		}
	}

    flinks {
    	conf = "dbis.piglet.backends.flink.streaming.FlinksConf"
		jar = "flinklib/target/scala-2.11/flinklib-assembly-0.3.jar"
		generator =  {
		              class  = "dbis.piglet.codegen.flink.FlinkStreamingCodeGenStrategy"
		              extension = "scala"
		}
	}

	spark {
		conf = "dbis.piglet.backends.spark.SparkRun"
		jar = "sparklib/target/scala-2.11/sparklib_2.11-0.3.jar"
		#jar = "piglet/sparklib_2.11-1.0.jar"
		generator =  {
		              class  =  "dbis.piglet.codegen.spark.SparkCodeGenStrategy"
		              extension = "scala"
		}
	}

    sparks {
    	conf = "dbis.piglet.backends.spark.SparkSRun"
		jar = "sparklib/target/scala-2.11/sparklib_2.11-0.3.jar"
		#jar = "piglet/sparklib_2.11-1.0.jar"
		generator =  {
		              class  = "dbis.piglet.codegen.spark.SparkStreamingCodeGenStrategy"
		              extension = "scala"
		}
	}

	mapreduce {
		conf = "dbis.piglet.backends.mapreduce.PigRun"
		jar = "mapreduce/target/scala-2.11/mapreduce_2.11-0.3.jar"
	}
}

features {
	spatial {
		jar = "lib_unmanaged/stark.jar"
	}
}


profiler {
	configfile = "profilerstats.json"
	defaults {
    global_strategy = "maxbenefit"
		cost_strategy = "MAX"
		prob_strategy = "MIN"

		benefit = undefined
		prob_threshold = NaN

		cache_mode = "MEMORY_AND_DISK"
		fraction = 10

    cache {
      size = "1000g"
      eviction = "none"
			admissioncheck = false
    }
	}

	mibpersecreading = 880.0
	mibpersecwriting = 100.0
}
